{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append('/Users/lei/home/studyhall/smart-earth-sensing/lib') \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') \n",
    " \n",
    "import os \n",
    "import re \n",
    "import pickle \n",
    "import numpy as np\n",
    "\n",
    "import torch \n",
    "from torch.nn.functional import one_hot \n",
    "from torch.utils.data import Dataset\n",
    " \n",
    "from tqdm import tqdm \n",
    "from matplotlib import pyplot as plt \n",
    " \n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "from utils import * \n",
    "from dataset import * \n",
    "from h5reader import * \n",
    "from codedump import * \n",
    "from augmentation import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:47<00:00, 15.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8040, 1000, 1)\n",
      "(8040,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "soil_maps = (\n",
    "    {'normal' : 0,\n",
    "    'walk'    : 1,\n",
    "    'dig'     : 2},\n",
    "    {0 : 'nomal', \n",
    "    1  : 'walk', \n",
    "    2  : 'dig'}\n",
    ") \n",
    " \n",
    "wall_maps = (\n",
    "    {'normal' : 0,\n",
    "    'shake'   : 1},\n",
    "    {0 : 'nomal', \n",
    "    1  : 'shake'}\n",
    ") \n",
    "\n",
    "h5_dir_path = \"/Users/lei/home/studyhall/smart-earth-sensing/zhoujie/data/h5s\" \n",
    "soil_spec_path = \"/Users/lei/home/studyhall/smart-earth-sensing/zhoujie/data/specs_soil.txt\" \n",
    "wall_spec_path = \"/Users/lei/home/studyhall/smart-earth-sensing/zhoujie/data/specs_wall.txt\" \n",
    "wall_locus_id = 700 \n",
    "soil_locus_id = 570 \n",
    "sr = 2000 \n",
    "measurements4halfsec = 1000 \n",
    " \n",
    "feature_set, label_set = h5s2raw(h5_dir_path, soil_locus_id, soil_maps, soil_spec_path) \n",
    "feature_set = np.array([list(div2chunks(raw, measurements4halfsec)) for raw in feature_set]).reshape(67 * 120, 1000, 1)\n",
    "label_set = np.array([[label for i in range(0, sr * 60 // measurements4halfsec)] for label in label_set]).flatten()\n",
    "print(np.shape(feature_set))\n",
    "print(np.shape(label_set)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8040/8040 [23:40<00:00,  5.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32160, 1000, 1)\n",
      "(32160,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32160/32160 [01:27<00:00, 369.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32160, 1, 51, 64)\n",
      "(32160,)\n"
     ]
    }
   ],
   "source": [
    "augmented_feature_set = []\n",
    "augmented_label_set = [] \n",
    "for i in tqdm(range(0, len(feature_set))):\n",
    "    audio = feature_set[i] \n",
    "    augmented_feature_set += [audio, \n",
    "                            pitch_shift(audio=audio, sr=sr, pitch_factor=2), \n",
    "                            time_shift(audio=audio, shift_max=50, shift_direction='rand'), \n",
    "                            noise_injection(audio=audio, noise_factor=0.01)] \n",
    "    augmented_label_set += [label_set[i] for j in range(0, 4)] \n",
    "print(np.shape(augmented_feature_set)) \n",
    "print(np.shape(augmented_label_set)) \n",
    "feature_set = np.array([[raw2mfcc(raw)] for raw in tqdm(augmented_feature_set)])\n",
    "label_set = augmented_label_set \n",
    "print(np.shape(feature_set)) \n",
    "print(np.shape(label_set)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/pk_files/soil_corpus.pkl', 'wb') as f:\n",
    "    pickle.dump((feature_set, label_set), f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/pk_files/soil_corpus.pkl', 'rb') as f:\n",
    "    feature_set, label_set = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train len: 22512\n",
      "y_train len: 22512\n",
      "X_val len: 9648\n",
      "y_val len: 9648\n",
      "torch.Size([1, 51, 64])\n",
      "torch.Size([1, 51, 64])\n",
      "torch.Size([3])\n",
      "torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(feature_set, label_set, test_size=0.3, random_state=52)\n",
    "X_train = [torch.tensor(sample, dtype=torch.float32) for sample in X_train]\n",
    "X_val = [torch.tensor(sample, dtype=torch.float32) for sample in X_val]\n",
    "y_train = [one_hot(torch.tensor(sample, dtype=torch.long), num_classes=3).to(torch.float32) for sample in y_train]\n",
    "y_val = [one_hot(torch.tensor(sample, dtype=torch.long), num_classes=3).to(torch.float32) for sample in y_val]\n",
    "print(\"X_train len:\", len(X_train)) \n",
    "print(\"y_train len:\", len(y_train)) \n",
    "print(\"X_val len:\", len(X_val)) \n",
    "print(\"y_val len:\", len(y_val)) \n",
    "print(X_train[0].size()) \n",
    "print(X_val[0].size()) \n",
    "print(y_train[0].size()) \n",
    "print(y_val[0].size()) \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = Zhoujie_Soil_Dataset(X_train, y_train, len(y_train), None)\n",
    "data_val = Zhoujie_Soil_Dataset(X_val, y_val, len(y_val), None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/pk_files/soil_datasets.pkl', 'wb') as f:\n",
    "    pickle.dump((data_train, data_val), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smart-earth-sensing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
